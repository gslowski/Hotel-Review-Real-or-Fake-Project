{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'which' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# !which pip\n",
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9605cbe9e946>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import atexit\n",
    "import sys\n",
    "import time\n",
    "import pyspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "import findspark\n",
    "from sparkhpc import sparkjob\n",
    "\n",
    "#Exit handler to clean up the Spark cluster if the script exits or crashes\n",
    "def exitHandler(sj,sc):\n",
    "    try:\n",
    "        print('Trapped Exit cleaning up Spark Context')\n",
    "        sc.stop()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        print('Trapped Exit cleaning up Spark Job')\n",
    "        sj.stop()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "#Parameters for the Spark cluster\n",
    "nodes=1\n",
    "tasks_per_node=4\n",
    "memory_per_task=4096 #4 gig per process, adjust accordingly\n",
    "# Please estimate walltime carefully to keep unused Spark clusters from sitting \n",
    "# idle so that others may use the resources.\n",
    "walltime=\"1:00\" #1 hours\n",
    "#os.environ['SBATCH_PARTITION']='cpu2019' #Set the appropriate ARC partition\n",
    "\n",
    "sj = sparkjob.sparkjob(\n",
    "     ncores=nodes*tasks_per_node,\n",
    "     cores_per_executor=tasks_per_node,\n",
    "     memory_per_core=memory_per_task,\n",
    "     walltime=walltime\n",
    "    )\n",
    "\n",
    "sj.wait_to_start()\n",
    "time.sleep(60)\n",
    "sc = sj.start_spark()\n",
    "\n",
    "#Register the exit handler                                                                                                     \n",
    "atexit.register(exitHandler,sj,sc)\n",
    "\n",
    "#You need this line if you want to use SparkSQL\n",
    "sqlCtx=SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = sqlCtx\n",
    "spark = sqlCtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /global/software/jupyterhub-spark/anaconda3/lib/python3.7/site-packages (3.3)\n",
      "Requirement already satisfied: six in /global/software/jupyterhub-spark/anaconda3/lib/python3.7/site-packages (from nltk) (1.12.0)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 21.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/drew.burritt/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade pip\n",
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize1(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    return words  \n",
    "tokenize_word = udf(lambda x: tokenize1(x)  , ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize2(text):\n",
    "    sents = nltk.sent_tokenize(text)\n",
    "    return sents  \n",
    "tokenize_sent = udf(lambda x: tokenize2(x)  , ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/drew.burritt/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/drew.burritt/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_en = stopwords.words('english')\n",
    "def remove_stopwords1(word_list):\n",
    "    filtered_words = [word for word in word_list if word not in stop_en]\n",
    "    return filtered_words\n",
    "remove_stopwords = udf(lambda x: remove_stopwords1(x) , ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise1(word_list):\n",
    "    filtered_words = [word for word in word_list if word.isalnum() and len(word)>2]\n",
    "    return filtered_words\n",
    "remove_noise = udf(lambda x: remove_noise1(x) , ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "def stem1(word_list):\n",
    "    snowball = SnowballStemmer(language='english')\n",
    "    stemmed_words = [snowball.stem(word) for word in word_list]\n",
    "    return stemmed_words\n",
    "stem = udf(lambda x: stem1(x) , ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/drew.burritt/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/software/jupyterhub-spark/anaconda3/lib/python3.7/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "def sentiment1(text):\n",
    "  sia = SentimentIntensityAnalyzer()\n",
    "  return sia.polarity_scores(text)['compound']\n",
    "sentiment = udf(lambda x: sentiment1(x) , FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower\n",
    "def process_data(df):\n",
    "  dfText = df.select(\"Index\",\"Review\" ,\"polarity\",\"real_fake\", tokenize_word(\"Review\").alias(\"tokenized_words\"))\n",
    "  dfText = dfText.withColumn(\"sentiment\" ,sentiment(\"Review\"))\n",
    "  dfText = dfText.withColumn(\"tokenized_sents\" ,tokenize_sent(\"Review\"))\n",
    "  dfText = dfText.withColumn(\"no_stopwords\", remove_stopwords(\"tokenized_words\"))\n",
    "  dfText = dfText.withColumn(\"no_noise\", remove_noise(\"no_stopwords\"))\n",
    "  dfText = dfText.withColumn(\"stemmed\", stem(\"no_noise\"))\n",
    "  #dfText = dfText.select('*', F.concat_ws(\"_\",\"real_fake\",\"polarity\").alias(\"target\"))\n",
    "  return dfText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_test = spark.read.option(\"escape\",\"\\\"\").option(\"header\",True).csv(\"Hotel_Reviews_Calgary.csv\")\n",
    "df_test_all = process_data(df_raw_test)\n",
    "#df_test = df_test_all.select(\"Review\",\"stemmed\",\"sentiment\",\"target\",\"real_fake\")\n",
    "df_test = df_test_all.select(\"Review\",\"stemmed\",\"sentiment\",\"polarity\",\"real_fake\")\n",
    "\n",
    "df_raw_train = spark.read.option(\"escape\",\"\\\"\").option(\"header\",True).csv(\"Original_data.csv\")\n",
    "df_train = process_data(df_raw_train)\n",
    "#df_train = df_train.select(\"Review\",\"stemmed\",\"sentiment\",\"target\",\"real_fake\")\n",
    "df_train = df_train.select(\"Review\",\"stemmed\",\"sentiment\",\"polarity\",\"real_fake\")\n",
    "\n",
    "#df_train.display()\n",
    "combined = df_train.union(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 5)\n"
     ]
    }
   ],
   "source": [
    "print((df_test.count(), len(df_test.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Review: string, stemmed: array<string>, sentiment: float, polarity: string, real_fake: string]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.cache()\n",
    "df_test.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+--------+---------+\n",
      "|              Review|             stemmed|sentiment|polarity|real_fake|\n",
      "+--------------------+--------------------+---------+--------+---------+\n",
      "|We stayed 2 night...|[stay, night, spr...|  -0.9593|negative|     real|\n",
      "+--------------------+--------------------+---------+--------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, IndexToString, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "train_split, test_split = df_train.randomSplit(weights = [0.80, 0.20], seed = 1)\n",
    "train_split.cache()\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"stemmed\", outputCol=\"rawFeatures\", numFeatures=20000)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"TF_IDF\", minDocFreq=2)\n",
    "label_strIdx1 = StringIndexer(inputCol=\"polarity\", outputCol=\"polarity_idx\")\n",
    "assembles = VectorAssembler(inputCols = ['TF_IDF','sentiment','polarity_idx'],outputCol=\"features\")\n",
    "label_strIdx2 = StringIndexer(inputCol=\"real_fake\", outputCol=\"label\")\n",
    "lr = LogisticRegression(regParam = 0.3)\n",
    "label_idxStr = IndexToString(inputCol = \"label\", outputCol = \"article_class\")\n",
    "\n",
    "pipeline = Pipeline(stages=[hashingTF, idf,label_strIdx1, assembles, label_strIdx2, lr ,label_idxStr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.transform(test_split)\n",
    "pred_original = model.transform(df_test)\n",
    "pred.cache()\n",
    "pred_original.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-----+----------+-------------+\n",
      "|              review|polarity|label|prediction|article_class|\n",
      "+--------------------+--------+-----+----------+-------------+\n",
      "| My wife and I's ...|positive|  0.0|       0.0|         fake|\n",
      "|A bunch of us got...|positive|  1.0|       0.0|         real|\n",
      "|A lovely hotel in...|negative|  1.0|       1.0|         real|\n",
      "|A recent stay at ...|negative|  0.0|       0.0|         fake|\n",
      "|Affinia hotel in ...|negative|  0.0|       0.0|         fake|\n",
      "|After considering...|negative|  0.0|       0.0|         fake|\n",
      "|After reading so ...|positive|  1.0|       1.0|         real|\n",
      "|After reading the...|negative|  1.0|       1.0|         real|\n",
      "|After reading the...|positive|  1.0|       1.0|         real|\n",
      "|After some delibe...|positive|  1.0|       1.0|         real|\n",
      "|All I can say is ...|negative|  1.0|       0.0|         real|\n",
      "|Amalifa Hotel in ...|positive|  0.0|       0.0|         fake|\n",
      "|Awesome hotel, ou...|positive|  1.0|       1.0|         real|\n",
      "|Booked a room onl...|positive|  1.0|       1.0|         real|\n",
      "|Chicago has many ...|negative|  0.0|       0.0|         fake|\n",
      "|Conrad Chicago is...|positive|  0.0|       0.0|         fake|\n",
      "|Couldn't have ask...|positive|  0.0|       0.0|         fake|\n",
      "|DO NOT STAY HERE!...|negative|  0.0|       0.0|         fake|\n",
      "|Don't ever stay a...|negative|  0.0|       0.0|         fake|\n",
      "|Downtown Chicago ...|positive|  0.0|       0.0|         fake|\n",
      "+--------------------+--------+-----+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred.select(\"review\",\"polarity\", \"label\", \"prediction\",\"article_class\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ce5584aa6ce2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "pred.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our data:  0.8651026392961877\n",
      "original data:  0.608\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "eval = MulticlassClassificationEvaluator(labelCol=\"label\",predictionCol=\"prediction\",metricName=\"accuracy\")\n",
    "#acc_our_data = eval.evaluate(pred)\n",
    "print(\"our data: \", acc_our_data)\n",
    "acc_original_data = eval.evaluate(pred_original)\n",
    "print(\"original data: \", acc_original_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(hashingTF.numFeatures, [10000,20000,50000]) \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.3 ,0.5]) \\\n",
    "    .build()\n",
    "crossval = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid,evaluator= MulticlassClassificationEvaluator(),numFolds=4,parallelism = 100 )  # use 3+ folds in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = crossval.fit(train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = cvModel.transform(test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = eval.evaluate(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7476979742173112"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>numFeatures</th>\n",
       "      <th>regParam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.698392</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.703720</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.704871</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.711836</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.717050</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.710479</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.707334</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.710366</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.709178</td>\n",
       "      <td>50000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1  numFeatures  regParam\n",
       "0  0.698392        10000       0.1\n",
       "1  0.703720        10000       0.3\n",
       "2  0.704871        10000       0.5\n",
       "3  0.711836        20000       0.1\n",
       "4  0.717050        20000       0.3\n",
       "5  0.710479        20000       0.5\n",
       "6  0.707334        50000       0.1\n",
       "7  0.710366        50000       0.3\n",
       "8  0.709178        50000       0.5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [{\n",
    "      p.name: v\n",
    "      for p,\n",
    "      v in m.items()\n",
    "   }\n",
    "   for m in cvModel.getEstimatorParamMaps()\n",
    "]\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame.from_dict([{\n",
    "      cvModel.getEvaluator().getMetricName(): metric,\n",
    "      ** ps\n",
    "   }\n",
    "   for ps, metric in zip(params, cvModel.avgMetrics)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, IndexToString, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "train_split, test_split = df_train.randomSplit(weights = [0.80, 0.20], seed = 1)\n",
    "train_split.cache()\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"stemmed\", outputCol=\"rawFeatures\")\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"TF_IDF\", minDocFreq=2)\n",
    "label_strIdx1 = StringIndexer(inputCol=\"polarity\", outputCol=\"polarity_idx\")\n",
    "assembles = VectorAssembler(inputCols = ['TF_IDF','sentiment','polarity_idx'],outputCol=\"features\")\n",
    "label_strIdx2 = StringIndexer(inputCol=\"real_fake\", outputCol=\"label\")\n",
    "svc = LinearSVC(featuresCol=\"features\",labelCol=\"label\")\n",
    "label_idxStr = IndexToString(inputCol = \"label\", outputCol = \"article_class\")\n",
    "\n",
    "pipeline_svc = Pipeline(stages=[hashingTF, idf,label_strIdx1 , assembles, label_strIdx2, svc ,label_idxStr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(hashingTF.numFeatures, [10000,20000,50000]) \\\n",
    "    .addGrid(svc.regParam, [0.0001, 0.001, 0.01, 0.1, 1]) \\\n",
    "    .build()\n",
    "crossval_svc = CrossValidator(estimator=pipeline_svc, estimatorParamMaps=paramGrid,evaluator= MulticlassClassificationEvaluator(),numFolds=2,parallelism = 100 )  # use 3+ folds in practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel_svc = crossval_svc.fit(train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Review: string, stemmed: array<string>, sentiment: float, polarity: string, real_fake: string, rawFeatures: vector, TF_IDF: vector, polarity_idx: double, features: vector, label: double, rawPrediction: vector, prediction: double, article_class: string]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_svc = cvModel_svc.transform(test_split)\n",
    "pred_original_svc = cvModel_svc.transform(df_test)\n",
    "pred_svc.cache()\n",
    "pred_original_svc.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our data:  0.8621700879765396\n",
      "original data:  0.625\n"
     ]
    }
   ],
   "source": [
    "eval = MulticlassClassificationEvaluator(labelCol=\"label\",predictionCol=\"prediction\",metricName=\"accuracy\")\n",
    "acc_our_data_svc = eval.evaluate(pred_svc)\n",
    "print(\"our data: \", acc_our_data_svc)\n",
    "acc_original_data_svc = eval.evaluate(pred_original_svc)\n",
    "print(\"original data: \", acc_original_data_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>numFeatures</th>\n",
       "      <th>regParam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.816170</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.813046</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.813040</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1  numFeatures  regParam\n",
       "0  0.816170        10000    0.0001\n",
       "1  0.813046        10000    0.0010\n",
       "2  0.813040        10000    0.0100"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [{\n",
    "      p.name: v\n",
    "      for p,\n",
    "      v in m.items()\n",
    "   }\n",
    "   for m in cvModel_svc.getEstimatorParamMaps()\n",
    "]\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame.from_dict([{\n",
    "      cvModel.getEvaluator().getMetricName(): metric,\n",
    "      ** ps\n",
    "   }\n",
    "   for ps, metric in zip(params, cvModel.avgMetrics)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Param(parent='LinearSVC_293ba5c073bb', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'),\n",
       " Param(parent='LinearSVC_293ba5c073bb', name='featuresCol', doc='features column name.'),\n",
       " Param(parent='LinearSVC_293ba5c073bb', name='fitIntercept', doc='whether to fit an intercept term.'),\n",
       " Param(parent='LinearSVC_293ba5c073bb', name='labelCol', doc='label column name.'),\n",
       " Param(parent='LinearSVC_293ba5c073bb', name='maxIter', doc='max number of iterations (>= 0).'),\n",
       " Param(parent='LinearSVC_293ba5c073bb', name='predictionCol', doc='prediction column name.'),\n",
       " Param(parent='LinearSVC_293ba5c073bb', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'),\n",
       " Param(parent='LinearSVC_293ba5c073bb', name='regParam', doc='regularization parameter (>= 0).'),\n",
       " Param(parent='LinearSVC_293ba5c073bb', name='standardization', doc='whether to standardize the training features before fitting the model.'),\n",
       " Param(parent='LinearSVC_293ba5c073bb', name='threshold', doc='The threshold in binary classification applied to the linear model prediction.  This threshold can be any real number, where Inf will make all predictions 0.0 and -Inf will make all predictions 1.0.'),\n",
       " Param(parent='LinearSVC_293ba5c073bb', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0).'),\n",
       " Param(parent='LinearSVC_293ba5c073bb', name='weightCol', doc='weight column name. If this is not set or empty, we treat all instance weights as 1.0.')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

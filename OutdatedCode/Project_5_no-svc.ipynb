{"cells":[{"cell_type":"code","source":["#!pip install --upgrade pip\n!pip install nltk\nimport nltk\nnltk.download('punkt')\nimport pyspark.sql.functions as F\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import udf"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bac02ede-98c1-48c0-83db-6f908fc2d8e7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Requirement already satisfied: nltk in /databricks/python3/lib/python3.8/site-packages (3.6.5)\r\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from nltk) (4.62.3)\r\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk) (8.0.3)\r\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.8/site-packages (from nltk) (2021.11.10)\r\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (1.0.1)\r\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\r\nYou should consider upgrading via the '/databricks/python3/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Requirement already satisfied: nltk in /databricks/python3/lib/python3.8/site-packages (3.6.5)\r\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.8/site-packages (from nltk) (4.62.3)\r\nRequirement already satisfied: click in /databricks/python3/lib/python3.8/site-packages (from nltk) (8.0.3)\r\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.8/site-packages (from nltk) (2021.11.10)\r\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.8/site-packages (from nltk) (1.0.1)\r\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\r\nYou should consider upgrading via the '/databricks/python3/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["def tokenize1(text):\n    words = nltk.word_tokenize(text)\n    return words  \ntokenize_word = udf(lambda x: tokenize1(x)  , ArrayType(StringType()))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c60ffe25-7325-4aec-b77a-644dd5e13ea0"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def tokenize2(text):\n    sents = nltk.sent_tokenize(text)\n    return sents  \ntokenize_sent = udf(lambda x: tokenize2(x)  , ArrayType(StringType()))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"daa00646-4b05-4d58-a4b3-4d46fdc087e2"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from nltk.corpus import stopwords\nnltk.download('stopwords')\nnltk.download('punkt')\nstop_en = stopwords.words('english')\ndef remove_stopwords1(word_list):\n    filtered_words = [word for word in word_list if word not in stop_en]\n    return filtered_words\nremove_stopwords = udf(lambda x: remove_stopwords1(x) , ArrayType(StringType()))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a80a0127-811b-419f-acb7-00cf6bc75483"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n[nltk_data] Downloading package punkt to /root/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["def remove_noise1(word_list):\n    filtered_words = [word for word in word_list if word.isalnum() and len(word)>2]\n    return filtered_words\nremove_noise = udf(lambda x: remove_noise1(x) , ArrayType(StringType()))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d4d2c5cb-ef88-4a30-8b6c-ed79820fcbcc"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from nltk.stem import SnowballStemmer\ndef stem1(word_list):\n    snowball = SnowballStemmer(language='english')\n    stemmed_words = [snowball.stem(word) for word in word_list]\n    return stemmed_words\nstem = udf(lambda x: stem1(x) , ArrayType(StringType()))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1b89a87f-4a18-4d30-87e0-657048e0f46d"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from nltk.sentiment import SentimentIntensityAnalyzer\nnltk.download('vader_lexicon')\ndef sentiment1(text):\n  sia = SentimentIntensityAnalyzer()\n  return sia.polarity_scores(text)['compound']\nsentiment = udf(lambda x: sentiment1(x) , FloatType())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"73d2abe7-c328-4136-8d8c-4c6767e40597"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["#greg\n#create udf for adding length of reviews by word count for all alphanumeric \"words\"\n\ndef get_length1(word_list):\n  alphanum_words = [word for word in word_list if word.isalnum()]\n  N = len(alphanum_words)\n  return N\n\nget_length = udf(lambda x: get_length1(x), IntegerType())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"72b9e90e-5527-4371-84d4-19d6f5eaa983"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#greg\n#create udf for adding average word length by review\n\ndef get_average_word_length1(word_list):\n  alphanum_word_lengths = [len(word) for word in word_list if word.isalnum()]\n  avg_word_len = sum(alphanum_word_lengths)/len(alphanum_word_lengths)\n  return avg_word_len\n\nget_average_word_length = udf(lambda x: get_average_word_length1(x), FloatType())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7d9f6e13-2683-4ca6-99a0-aa70d06b3795"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#greg\n#create udf for ratio of capitalized characters to total characters (n), with no white spaces\n\ndef capital_ratio1(word_list):\n  s = \"\".join(word_list)\n  n = len(s)\n  cap_n = len([char for char in s if char.isupper()])\n  ratio_cap_to_total = cap_n / n\n  return ratio_cap_to_total\n\ncapital_ratio = udf(lambda x: capital_ratio1(x), FloatType())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"44432129-8b18-4276-8e43-3fc39b162562"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#greg\n#create udf for ratio of long words (>5 letters) to total words (N)\n\ndef long_word_ratio1(word_list):\n  alphanum_words = [word for word in word_list if word.isalnum()]\n  N = len(alphanum_words)\n  long_words = [word for word in alphanum_words if len(word) > 5]\n  long_words_count = len(long_words)\n  ratio_long_to_total = long_words_count / N\n  return ratio_long_to_total\n\nlong_word_ratio = udf(lambda x: long_word_ratio1(x), FloatType())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9683f778-921c-4514-8ada-c2d2d6ed09fb"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#greg\n#create udf for ratio of words after stop word removal vs total words\n\nstop_en = stopwords.words('english')\n\ndef filtered_word_ratio1(word_list):\n  alphanum_words = [word for word in word_list if word.isalnum()]\n  N = len(alphanum_words)\n  non_filtered_words = [word for word in alphanum_words if word not in stop_en]\n  num_non_filtered_words = len(non_filtered_words)\n  ratio_non_filtered_to_total = num_non_filtered_words / N\n  return ratio_non_filtered_to_total\n\nfiltered_word_ratio = udf(lambda x: filtered_word_ratio1(x), FloatType())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2d6b653c-8d26-4c25-850a-3b24555527f2"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#greg\n#create udf for ratio of punctuation \"words\" vs total alphanumeric words\n\ndef punctuation_word_ratio1(word_list):\n  alphanum_words = [word for word in word_list if word.isalnum()]\n  N = len(alphanum_words)\n  punctuation_words = [word for word in word_list if not(word.isalnum())]\n  num_punctuation_words = len(punctuation_words)\n  ratio_punctuation_to_total = num_punctuation_words / N\n  return ratio_punctuation_to_total\n\npunctuation_word_ratio = udf(lambda x: punctuation_word_ratio1(x), FloatType())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ae3bb459-5902-4241-8606-33107c57304c"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.functions import lower\ndef process_data(df):\n  dfText = df.select(\"Index\",\"Review\" ,\"polarity\",\"real_fake\", tokenize_word(\"Review\").alias(\"tokenized_words\"))\n  dfText = dfText.withColumn(\"sentiment\" ,sentiment(\"Review\"))\n  dfText = dfText.withColumn(\"tokenized_sents\" ,tokenize_sent(\"Review\"))\n  dfText = dfText.withColumn(\"no_stopwords\", remove_stopwords(\"tokenized_words\"))\n  dfText = dfText.withColumn(\"no_noise\", remove_noise(\"no_stopwords\"))\n  dfText = dfText.withColumn(\"stemmed\", stem(\"no_noise\"))\n  #dfText = dfText.select('*', F.concat_ws(\"_\",\"real_fake\",\"polarity\").alias(\"target\"))\n  dfText = dfText.withColumn(\"length_in_words\", get_length(\"tokenized_words\"))\n  dfText = dfText.withColumn(\"average_word_length\", get_average_word_length(\"tokenized_words\"))\n  dfText = dfText.withColumn(\"capital_char_ratio\", capital_ratio(\"tokenized_words\"))\n  dfText = dfText.withColumn(\"long_word_ratio\", long_word_ratio(\"tokenized_words\"))\n  dfText = dfText.withColumn(\"non_stop_word_ratio\", filtered_word_ratio(\"tokenized_words\"))\n  dfText = dfText.withColumn(\"punctuation_ratio\", punctuation_word_ratio(\"tokenized_words\"))\n\n  return dfText"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7ff6da39-9b25-4af2-86a7-9676e04a6cac"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["df_raw_old = spark.read.option(\"escape\",\"\\\"\").option(\"header\",True).csv(\"/FileStore/tables/Original_data.csv\")\ndf_old_all = process_data(df_raw_old)\n#df_test = df_test_all.select(\"Review\",\"stemmed\",\"sentiment\",\"target\",\"real_fake\")\ndf_old = df_old_all.select(\"Review\",\"stemmed\",\"sentiment\",\"polarity\", \"length_in_words\", \"average_word_length\", \\\n                             \"capital_char_ratio\", \"long_word_ratio\", \"non_stop_word_ratio\", \"punctuation_ratio\", \"real_fake\")\n\nold_train_split, old_test_split = df_old.randomSplit(weights = [0.80, 0.20], seed = 1)\nold_train_split.cache()\nold_test_split.cache()\n\ndf_raw_new = spark.read.option(\"escape\",\"\\\"\").option(\"header\",True).csv(\"/FileStore/tables/Hotel_Reviews_Calgary.csv\")\ndf_new_all = process_data(df_raw_new)\n#df_train = df_train.select(\"Review\",\"stemmed\",\"sentiment\",\"target\",\"real_fake\")\ndf_new = df_new_all.select(\"Review\",\"stemmed\",\"sentiment\",\"polarity\", \"length_in_words\", \"average_word_length\", \\\n                             \"capital_char_ratio\", \"long_word_ratio\", \"non_stop_word_ratio\", \"punctuation_ratio\", \"real_fake\")\n\nnew_train_split, new_test_split = df_new.randomSplit(weights = [0.80, 0.20], seed = 1)\nnew_train_split.cache()\nnew_test_split.cache()\n\n#df_train.display()\ncombined_train = old_train_split.union(new_train_split)\ncombined_test = old_test_split.union(new_test_split)\n\ncombined_train.cache()\ncombined_test.cache()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dd8b7afc-ad00-4662-a0a6-cd09430788b2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[17]: DataFrame[Review: string, stemmed: array<string>, sentiment: float, polarity: string, length_in_words: int, average_word_length: float, capital_char_ratio: float, long_word_ratio: float, non_stop_word_ratio: float, punctuation_ratio: float, real_fake: string]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[17]: DataFrame[Review: string, stemmed: array<string>, sentiment: float, polarity: string, length_in_words: int, average_word_length: float, capital_char_ratio: float, long_word_ratio: float, non_stop_word_ratio: float, punctuation_ratio: float, real_fake: string]"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["print((combined_train.count(), len(combined_train.columns)))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"67eb8ccb-a883-43b8-b95e-edf191681dfd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"(2119, 11)\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["(2119, 11)\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["combined_train.show(1)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"efb7e3d5-68bf-4758-adc1-0ffeabb32b4a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+--------------------+--------------------+---------+--------+---------------+-------------------+------------------+---------------+-------------------+-----------------+---------+\n|              Review|             stemmed|sentiment|polarity|length_in_words|average_word_length|capital_char_ratio|long_word_ratio|non_stop_word_ratio|punctuation_ratio|real_fake|\n+--------------------+--------------------+---------+--------+---------------+-------------------+------------------+---------------+-------------------+-----------------+---------+\n| Barely Average H...|[bare, averag, ho...|   0.1901|negative|            187|           4.390374|         0.0391924|     0.26737967|          0.5828877|      0.112299465|     real|\n+--------------------+--------------------+---------+--------+---------------+-------------------+------------------+---------------+-------------------+-----------------+---------+\nonly showing top 1 row\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+--------------------+--------------------+---------+--------+---------------+-------------------+------------------+---------------+-------------------+-----------------+---------+\n|              Review|             stemmed|sentiment|polarity|length_in_words|average_word_length|capital_char_ratio|long_word_ratio|non_stop_word_ratio|punctuation_ratio|real_fake|\n+--------------------+--------------------+---------+--------+---------------+-------------------+------------------+---------------+-------------------+-----------------+---------+\n| Barely Average H...|[bare, averag, ho...|   0.1901|negative|            187|           4.390374|         0.0391924|     0.26737967|          0.5828877|      0.112299465|     real|\n+--------------------+--------------------+---------+--------+---------------+-------------------+------------------+---------------+-------------------+-----------------+---------+\nonly showing top 1 row\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"03388fa3-693c-4b6c-b08a-59cb938ca0b0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"badad2f2-6e9e-4dd6-96af-ff9bbb484b01"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["# Logistic Regression"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"95a45e0d-c442-4f8a-86d7-c9dccddf4f43"}}},{"cell_type":"code","source":["from pyspark.ml.feature import HashingTF, IDF, IndexToString, StringIndexer\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StandardScaler\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.classification import LinearSVC\nfrom pyspark.ml.classification import NaiveBayes\nfrom pyspark.ml.classification import GBTClassifier\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\ncolumns_to_be_scaled = ['length_in_words', 'average_word_length', 'capital_char_ratio', 'long_word_ratio', 'non_stop_word_ratio', 'punctuation_ratio']\nassemblers = [VectorAssembler(inputCols=[col], outputCol=col + \"_vec\") for col in columns_to_be_scaled]\nscalers  = [StandardScaler(inputCol=col + \"_vec\", outputCol=col + \"_scaled\") for col in columns_to_be_scaled]\nscaling_pipeline = Pipeline(stages=assemblers + scalers)\n\nhashingTF = HashingTF(inputCol=\"stemmed\", outputCol=\"rawFeatures\", numFeatures=20000)\nidf = IDF(inputCol=\"rawFeatures\", outputCol=\"TF_IDF\", minDocFreq=2)\nlabel_strIdx1 = StringIndexer(inputCol=\"polarity\", outputCol=\"polarity_idx\")\nassembles = VectorAssembler(inputCols = ['TF_IDF','sentiment','polarity_idx', 'length_in_words_scaled', 'average_word_length_scaled', 'capital_char_ratio_scaled', 'long_word_ratio_scaled', 'non_stop_word_ratio_scaled', 'punctuation_ratio_scaled'],outputCol=\"features\")\nlabel_strIdx2 = StringIndexer(inputCol=\"real_fake\", outputCol=\"label\")\nlr = LogisticRegression(regParam = 0.3)\nlabel_idxStr = IndexToString(inputCol = \"label\", outputCol = \"article_class\")\n\npipeline = Pipeline(stages=[scaling_pipeline, hashingTF, idf,label_strIdx1, assembles, label_strIdx2, lr ,label_idxStr])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"efeecdd5-5183-44ef-afc5-4570810904c1"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\nparamGrid = ParamGridBuilder() \\\n    .addGrid(hashingTF.numFeatures, [10000,20000,50000]) \\\n    .addGrid(lr.regParam, [0.1, 0.3 ,0.5]) \\\n    .build()\ncrossval_lr = CrossValidator(estimator=pipeline, estimatorParamMaps=paramGrid,evaluator= MulticlassClassificationEvaluator(),numFolds=3,parallelism = 100 )  # use 3+ folds in practice\n\n### ON REFINEMENT DO 5 FOLD? MAYBE JUST FOR BEST PRELIMINARY MODEL?###"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"19fdf3c3-933b-4078-83be-a6d3328ce964"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["cvModel_lr = crossval_lr.fit(combined_train)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"32020647-3229-4074-9526-7a3271fe40ab"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["pred_old_lr = cvModel_lr.transform(old_test_split)\npred_new_lr = cvModel_lr.transform(new_test_split)\npred_combined_lr = cvModel_lr.transform(combined_test)\n\npred_old_lr.cache()\npred_new_lr.cache()\npred_combined_lr.cache()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"82d76da1-da65-4664-9231-288bbbed7a2a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\neval = MulticlassClassificationEvaluator(labelCol=\"label\",predictionCol=\"prediction\",metricName=\"accuracy\")\nacc_our_data = eval.evaluate(pred_new_lr)\nprint(\"our data: \", acc_our_data)\nacc_original_data = eval.evaluate(pred_old_lr)\nprint(\"original data: \", acc_original_data)\nacc_original_data = eval.evaluate(pred_combined_lr)\nprint(\"combined data: \", acc_original_data)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ac5effea-f9df-4e16-8fca-b803b5ffc741"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["params = [{\n      p.name: v\n      for p,\n      v in m.items()\n   }\n   for m in cvModel_lr.getEstimatorParamMaps()\n]\nimport pandas as pd\n\npd.DataFrame.from_dict([{\n      cvModel_lr.getEvaluator().getMetricName(): metric,\n      ** ps\n   }\n   for ps, metric in zip(params, cvModel_lr.avgMetrics)\n])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5b17ea6f-b96e-4a13-a242-a4e2216847ce"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["# Random Forest Classifier"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f7658b42-f71f-4a83-bf39-abb1fc9ff528"}}},{"cell_type":"code","source":["#greg\n\nfrom pyspark.ml.feature import HashingTF, IDF, IndexToString, StringIndexer\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import StandardScaler\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.classification import LinearSVC\nfrom pyspark.ml.classification import NaiveBayes\nfrom pyspark.ml.classification import GBTClassifier\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\ncolumns_to_be_scaled = ['length_in_words', 'average_word_length', 'capital_char_ratio', 'long_word_ratio', 'non_stop_word_ratio', 'punctuation_ratio']\nassemblers = [VectorAssembler(inputCols=[col], outputCol=col + \"_vec\") for col in columns_to_be_scaled]\nscalers  = [StandardScaler(inputCol=col + \"_vec\", outputCol=col + \"_scaled\") for col in columns_to_be_scaled]\nscaling_pipeline = Pipeline(stages=assemblers + scalers)\n\nhashingTF = HashingTF(inputCol=\"stemmed\", outputCol=\"rawFeatures\")\nidf = IDF(inputCol=\"rawFeatures\", outputCol=\"TF_IDF\", minDocFreq=2)\nlabel_strIdx1 = StringIndexer(inputCol=\"polarity\", outputCol=\"polarity_idx\")\nassembles = VectorAssembler(inputCols = ['TF_IDF','sentiment','polarity_idx', 'length_in_words_scaled', 'average_word_length_scaled', 'capital_char_ratio_scaled', 'long_word_ratio_scaled', 'non_stop_word_ratio_scaled', 'punctuation_ratio_scaled'],outputCol=\"features\")\nlabel_strIdx2 = StringIndexer(inputCol=\"real_fake\", outputCol=\"label\")\nrfc = RandomForestClassifier(featuresCol=\"features\",labelCol=\"label\")\nlabel_idxStr = IndexToString(inputCol = \"label\", outputCol = \"article_class\")\n\npipeline_rfc = Pipeline(stages=[scaling_pipeline, hashingTF, idf,label_strIdx1 , assembles, label_strIdx2, rfc ,label_idxStr])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0599ab1f-da8e-42d3-8f66-10de5283b7bd"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\nparamGrid = ParamGridBuilder() \\\n    .addGrid(hashingTF.numFeatures, [10000,20000,50000]) \\\n    .addGrid(rfc.maxDepth, [3, 5, 9]) \\\n    .addGrid(rfc.numTrees, [10, 20, 50]) \\\n    .build()\ncrossval_rfc = CrossValidator(estimator=pipeline_rfc, estimatorParamMaps=paramGrid,evaluator= MulticlassClassificationEvaluator(),numFolds=2,parallelism = 100 )  # use 3+ folds in practice"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6e1e2603-e78f-4d46-9076-b9e68ffe560e"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["cvModel_rfc = crossval_rfc.fit(combined_train)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e0feb797-f609-4b3c-888b-657252e158cb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"/databricks/spark/python/pyspark/ml/util.py:839: UserWarning: Cannot find mlflow module. To enable MLflow logging, install mlflow from PyPI.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["/databricks/spark/python/pyspark/ml/util.py:839: UserWarning: Cannot find mlflow module. To enable MLflow logging, install mlflow from PyPI.\n  warnings.warn(_MLflowInstrumentation._NO_MLFLOW_WARNING)\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["pred_old_rfc = cvModel_rfc.transform(old_test_split)\npred_new_rfc = cvModel_rfc.transform(new_test_split)\npred_combined_rfc = cvModel_rfc.transform(combined_test)\n\npred_old_rfc.cache()\npred_new_rfc.cache()\npred_combined_rfc.cache()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"138d2052-99b7-4063-a696-7c484b5de9b3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[23]: DataFrame[Review: string, stemmed: array<string>, sentiment: float, polarity: string, length_in_words: int, average_word_length: float, capital_char_ratio: float, long_word_ratio: float, non_stop_word_ratio: float, punctuation_ratio: float, real_fake: string, length_in_words_vec: vector, average_word_length_vec: vector, capital_char_ratio_vec: vector, long_word_ratio_vec: vector, non_stop_word_ratio_vec: vector, punctuation_ratio_vec: vector, length_in_words_scaled: vector, average_word_length_scaled: vector, capital_char_ratio_scaled: vector, long_word_ratio_scaled: vector, non_stop_word_ratio_scaled: vector, punctuation_ratio_scaled: vector, rawFeatures: vector, TF_IDF: vector, polarity_idx: double, features: vector, label: double, rawPrediction: vector, probability: vector, prediction: double, article_class: string]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[23]: DataFrame[Review: string, stemmed: array<string>, sentiment: float, polarity: string, length_in_words: int, average_word_length: float, capital_char_ratio: float, long_word_ratio: float, non_stop_word_ratio: float, punctuation_ratio: float, real_fake: string, length_in_words_vec: vector, average_word_length_vec: vector, capital_char_ratio_vec: vector, long_word_ratio_vec: vector, non_stop_word_ratio_vec: vector, punctuation_ratio_vec: vector, length_in_words_scaled: vector, average_word_length_scaled: vector, capital_char_ratio_scaled: vector, long_word_ratio_scaled: vector, non_stop_word_ratio_scaled: vector, punctuation_ratio_scaled: vector, rawFeatures: vector, TF_IDF: vector, polarity_idx: double, features: vector, label: double, rawPrediction: vector, probability: vector, prediction: double, article_class: string]"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["eval = MulticlassClassificationEvaluator(labelCol=\"label\",predictionCol=\"prediction\",metricName=\"accuracy\")\nacc_new_data = eval.evaluate(pred_new_rfc)\nprint(\"new data: \", acc_new_data)\nacc_old_data = eval.evaluate(pred_old_rfc)\nprint(\"old data: \", acc_old_data)\nacc_combined_data = eval.evaluate(pred_combined_rfc)\nprint(\"combined data: \", acc_combined_data)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b76923da-9953-4425-a33a-5804b06e0c3a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"new data:  0.8100558659217877\nold data:  0.5761589403973509\ncombined data:  0.6632016632016632\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["new data:  0.8100558659217877\nold data:  0.5761589403973509\ncombined data:  0.6632016632016632\n"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["params = [{\n      p.name: v\n      for p,\n      v in m.items()\n   }\n   for m in cvModel_rfc.getEstimatorParamMaps()\n]\nimport pandas as pd\n\npd.DataFrame.from_dict([{\n      cvModel_rfc.getEvaluator().getMetricName(): metric,\n      ** ps\n   } for ps, metric in zip(params, cvModel_rfc.avgMetrics)\n])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d6013933-4374-488a-88f6-f9085b0b7fbe"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f1</th>\n      <th>numFeatures</th>\n      <th>maxDepth</th>\n      <th>numTrees</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.490034</td>\n      <td>10000</td>\n      <td>3</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.483980</td>\n      <td>10000</td>\n      <td>3</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.484092</td>\n      <td>10000</td>\n      <td>3</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.538304</td>\n      <td>10000</td>\n      <td>5</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.515189</td>\n      <td>10000</td>\n      <td>5</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.504999</td>\n      <td>10000</td>\n      <td>5</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.593719</td>\n      <td>10000</td>\n      <td>9</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.616286</td>\n      <td>10000</td>\n      <td>9</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.573703</td>\n      <td>10000</td>\n      <td>9</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.498955</td>\n      <td>20000</td>\n      <td>3</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.484092</td>\n      <td>20000</td>\n      <td>3</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.482000</td>\n      <td>20000</td>\n      <td>3</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.532960</td>\n      <td>20000</td>\n      <td>5</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.509800</td>\n      <td>20000</td>\n      <td>5</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.491728</td>\n      <td>20000</td>\n      <td>5</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.591264</td>\n      <td>20000</td>\n      <td>9</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.559510</td>\n      <td>20000</td>\n      <td>9</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.548325</td>\n      <td>20000</td>\n      <td>9</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.485868</td>\n      <td>50000</td>\n      <td>3</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.482876</td>\n      <td>50000</td>\n      <td>3</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.480884</td>\n      <td>50000</td>\n      <td>3</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.508559</td>\n      <td>50000</td>\n      <td>5</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.501534</td>\n      <td>50000</td>\n      <td>5</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.484092</td>\n      <td>50000</td>\n      <td>5</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.556509</td>\n      <td>50000</td>\n      <td>9</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.541101</td>\n      <td>50000</td>\n      <td>9</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.510803</td>\n      <td>50000</td>\n      <td>9</td>\n      <td>50</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f1</th>\n      <th>numFeatures</th>\n      <th>maxDepth</th>\n      <th>numTrees</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.490034</td>\n      <td>10000</td>\n      <td>3</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.483980</td>\n      <td>10000</td>\n      <td>3</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.484092</td>\n      <td>10000</td>\n      <td>3</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.538304</td>\n      <td>10000</td>\n      <td>5</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.515189</td>\n      <td>10000</td>\n      <td>5</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.504999</td>\n      <td>10000</td>\n      <td>5</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.593719</td>\n      <td>10000</td>\n      <td>9</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.616286</td>\n      <td>10000</td>\n      <td>9</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.573703</td>\n      <td>10000</td>\n      <td>9</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.498955</td>\n      <td>20000</td>\n      <td>3</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.484092</td>\n      <td>20000</td>\n      <td>3</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.482000</td>\n      <td>20000</td>\n      <td>3</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.532960</td>\n      <td>20000</td>\n      <td>5</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.509800</td>\n      <td>20000</td>\n      <td>5</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.491728</td>\n      <td>20000</td>\n      <td>5</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.591264</td>\n      <td>20000</td>\n      <td>9</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.559510</td>\n      <td>20000</td>\n      <td>9</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.548325</td>\n      <td>20000</td>\n      <td>9</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.485868</td>\n      <td>50000</td>\n      <td>3</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.482876</td>\n      <td>50000</td>\n      <td>3</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.480884</td>\n      <td>50000</td>\n      <td>3</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.508559</td>\n      <td>50000</td>\n      <td>5</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.501534</td>\n      <td>50000</td>\n      <td>5</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.484092</td>\n      <td>50000</td>\n      <td>5</td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.556509</td>\n      <td>50000</td>\n      <td>9</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.541101</td>\n      <td>50000</td>\n      <td>9</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.510803</td>\n      <td>50000</td>\n      <td>9</td>\n      <td>50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["print(\"Best regularization parameter: \", cvModel_rfc.bestModel.stages[6]._java_obj.getRegParam())\nprint(\"Best hashing number of features: \", cvModel_rfc.bestModel.stages[1]._java_obj.getNumFeatures())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"21aad708-7bee-4e5d-9573-e68b33449ec9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mPy4JError\u001B[0m                                 Traceback (most recent call last)\n\u001B[0;32m<command-3521022214098944>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Best regularization parameter: \"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcvModel_rfc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbestModel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstages\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m6\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_java_obj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetRegParam\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Best hashing number of features: \"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcvModel_rfc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbestModel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstages\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_java_obj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetNumFeatures\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1303\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1304\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1305\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    115\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mpy4j\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPy4JJavaError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    328\u001B[0m                     format(target_id, \".\", name), value)\n\u001B[1;32m    329\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 330\u001B[0;31m                 raise Py4JError(\n\u001B[0m\u001B[1;32m    331\u001B[0m                     \u001B[0;34m\"An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    332\u001B[0m                     format(target_id, \".\", name, value))\n\n\u001B[0;31mPy4JError\u001B[0m: An error occurred while calling o98335.getRegParam. Trace:\npy4j.Py4JException: Method getRegParam([]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:341)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:349)\n\tat py4j.Gateway.invoke(Gateway.java:286)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n\n","errorSummary":"py4j.Py4JException: Method getRegParam([]) does not exist","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mPy4JError\u001B[0m                                 Traceback (most recent call last)\n\u001B[0;32m<command-3521022214098944>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Best regularization parameter: \"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcvModel_rfc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbestModel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstages\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m6\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_java_obj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetRegParam\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Best hashing number of features: \"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcvModel_rfc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbestModel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstages\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_java_obj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetNumFeatures\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1303\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1304\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1305\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1306\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    115\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    116\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 117\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    118\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mpy4j\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprotocol\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mPy4JJavaError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    328\u001B[0m                     format(target_id, \".\", name), value)\n\u001B[1;32m    329\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 330\u001B[0;31m                 raise Py4JError(\n\u001B[0m\u001B[1;32m    331\u001B[0m                     \u001B[0;34m\"An error occurred while calling {0}{1}{2}. Trace:\\n{3}\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    332\u001B[0m                     format(target_id, \".\", name, value))\n\n\u001B[0;31mPy4JError\u001B[0m: An error occurred while calling o98335.getRegParam. Trace:\npy4j.Py4JException: Method getRegParam([]) does not exist\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:341)\n\tat py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:349)\n\tat py4j.Gateway.invoke(Gateway.java:286)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\n\n"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["# Gradient Boosting Classifier"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e922df5a-b593-45c5-9133-715eb2447df1"}}},{"cell_type":"code","source":["# #greg\n\n# from pyspark.ml.feature import HashingTF, IDF, IndexToString, StringIndexer\n# from pyspark.ml import Pipeline\n# from pyspark.ml.feature import StandardScaler\n# from pyspark.ml.classification import LogisticRegression\n# from pyspark.ml.classification import RandomForestClassifier\n# from pyspark.ml.classification import LinearSVC\n# from pyspark.ml.classification import NaiveBayes\n# from pyspark.ml.classification import GBTClassifier\n# from pyspark.ml.feature import VectorAssembler\n# from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\n# columns_to_be_scaled = ['length_in_words', 'average_word_length', 'capital_char_ratio', 'long_word_ratio', 'non_stop_word_ratio', 'punctuation_ratio']\n# assemblers = [VectorAssembler(inputCols=[col], outputCol=col + \"_vec\") for col in columns_to_be_scaled]\n# scalers  = [StandardScaler(inputCol=col + \"_vec\", outputCol=col + \"_scaled\") for col in columns_to_be_scaled]\n# scaling_pipeline = Pipeline(stages=assemblers + scalers)\n\n# hashingTF = HashingTF(inputCol=\"stemmed\", outputCol=\"rawFeatures\")\n# idf = IDF(inputCol=\"rawFeatures\", outputCol=\"TF_IDF\", minDocFreq=2)\n# label_strIdx1 = StringIndexer(inputCol=\"polarity\", outputCol=\"polarity_idx\")\n# assembles = VectorAssembler(inputCols = ['TF_IDF','sentiment','polarity_idx', 'length_in_words_scaled', 'average_word_length_scaled', 'capital_char_ratio_scaled', 'long_word_ratio_scaled', 'non_stop_word_ratio_scaled', 'punctuation_ratio_scaled'],outputCol=\"features\")\n# label_strIdx2 = StringIndexer(inputCol=\"real_fake\", outputCol=\"label\")\n# gbtc = GBTClassifier(featuresCol=\"features\",labelCol=\"label\")\n# label_idxStr = IndexToString(inputCol = \"label\", outputCol = \"article_class\")\n\n# pipeline_gbtc = Pipeline(stages=[scaling_pipeline, hashingTF, idf,label_strIdx1 , assembles, label_strIdx2, gbtc ,label_idxStr])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"90b652ab-a772-4043-8e29-f085d3822a17"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n\n# paramGrid = ParamGridBuilder() \\\n#     .addGrid(hashingTF.numFeatures, [10000,16384,32768]) \\\n#     .addGrid(gbtc.maxDepth, [3, 5, 7]) \\\n#     .addGrid(gbtc.stepSize, [0.1, 0.5, 1.0]) \\\n#     .build()\n# crossval_gbtc = CrossValidator(estimator=pipeline_gbtc, estimatorParamMaps=paramGrid,evaluator= MulticlassClassificationEvaluator(),numFolds=2,parallelism = 100 )  # use 3+ folds in practice"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b96545f-0290-463f-91d8-9dbbb9d5ee28"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# cvModel_gbtc = crossval_gbtc.fit(combined_train)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6e35df8d-584c-4660-b87a-bced02d0593e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# pred_old_gbtc = cvModel_gbtc.transform(old_test_split)\n# pred_new_gbtc = cvModel_gbtc.transform(new_test_split)\n# pred_combined_gbtc = cvModel_gbtc.transform(combined_test)\n\n# pred_old_gbtc.cache()\n# pred_new_gbtc.cache()\n# pred_combined_gbtc.cache()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ae61eafd-dfc0-4400-a157-054eaa25ea5b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# eval = MulticlassClassificationEvaluator(labelCol=\"label\",predictionCol=\"prediction\",metricName=\"accuracy\")\n# acc_new_data = eval.evaluate(pred_new_gbtc)\n# print(\"new data: \", acc_new_data)\n# acc_old_data = eval.evaluate(pred_old_gbtc)\n# print(\"old data: \", acc_old_data)\n# acc_combined_data = eval.evaluate(pred_combined_gbtc)\n# print(\"combined data: \", acc_combined_data)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c11bf18f-5dc3-45ef-97bf-7655451a4260"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# params = [{\n#       p.name: v\n#       for p,\n#       v in m.items()\n#    }\n#    for m in cvModel_gbtc.getEstimatorParamMaps()\n# ]\n# import pandas as pd\n\n# pd.DataFrame.from_dict([{\n#       cvModel_gbtc.getEvaluator().getMetricName(): metric,\n#       ** ps\n#    } for ps, metric in zip(params, cvModel_gbtc.avgMetrics)\n# ])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dfd049cb-f5d4-43ea-bb01-85678530406c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"","metadata":{},"errorTraceType":null,"type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]},"transient":null}],"execution_count":0},{"cell_type":"code","source":["# print(\"Best regularization parameter: \", cvModel_gbtc.bestModel.stages[6]._java_obj.getRegParam())\n# print(\"Best hashing number of features: \", cvModel_gbtc.bestModel.stages[1]._java_obj.getNumFeatures())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"107cff6f-85a1-421a-9c9e-a2b6058e00de"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n\u001B[0;32m<command-3521022214098952>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Best regularization parameter: \"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcvModel_gbtc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbestModel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstages\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m6\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_java_obj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetRegParam\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Best hashing number of features: \"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcvModel_gbtc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbestModel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstages\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_java_obj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetNumFeatures\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mNameError\u001B[0m: name 'cvModel_gbtc' is not defined","errorSummary":"<span class='ansi-red-fg'>NameError</span>: name 'cvModel_gbtc' is not defined","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n\u001B[0;32m<command-3521022214098952>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Best regularization parameter: \"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcvModel_gbtc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbestModel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstages\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m6\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_java_obj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetRegParam\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Best hashing number of features: \"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcvModel_gbtc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbestModel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstages\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_java_obj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetNumFeatures\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mNameError\u001B[0m: name 'cvModel_gbtc' is not defined"]},"transient":null}],"execution_count":0},{"cell_type":"markdown","source":["#"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de3dde35-3361-462f-9881-616e6e9569b5"}}}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.0","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"Project_1","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":167243994796758}},"nbformat":4,"nbformat_minor":0}
